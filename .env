"""
This file is a template for the .env file.

Please copy this file to .env and fill in the values.

For more information about configuration options, please refer to the documentation

"""

# Global configs:
USE_AZURE=False
CHAT_USE_AZURE_TOKEN_PROVIDER=False
EMBEDDING_USE_AZURE_TOKEN_PROVIDER=False
MAX_RETRY=10
RETRY_WAIT_SECONDS=20

# LLM API Setting:
#OPENAI_API_KEY=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
#CHAT_MODEL=gpt-4-turbo
#CHAT_MAX_TOKENS=3000
#CHAT_TEMPERATURE=0.7
# CHAT_AZURE_API_BASE=<for_Azure_user>
# CHAT_AZURE_API_VERSION=<for_Azure_user>
BACKEND=rdagent.oai.backend.LiteLLMAPIBackend
CHAT_MODEL=deepseek/deepseek-chat
DEEPSEEK_API_KEY=sk-9de65ef2a0764b0891779f42a77379b1

EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_AZURE_API_BASE=<for_Azure_user>
# EMBEDDING_AZURE_API_VERSION=<for_Azure_user>

# Cache Setting (Optional):

# Senario Configs: